[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/ravendb-cluster)](https://artifacthub.io/packages/search?repo=ravendb-cluster)
# Secured RavenDB Cluster Helm Chart ☸️


**Note:** For faster & more streamlined deployments, with not only day-0, but also day-1 support, please consider using [RavenDB Kubernetes Operator](https://github.com/ravendb/ravendb-operator). It provides a fully automated way to deploy and manage secure RavenDB clusters on Kubernetes. It handles certificate management, bootstrapping, rolling upgrades with safety gates, external access, persistent storage orchestration, node lifecycle management, and continuous health and status evaluation - all driven from a single RavenDBCluster custom resource. 


## Overview
This Helm chart provides all necessary components for the secured RavenDB cluster. It's very easy to deploy & manage your own RavenDB cluster by using it. You only need a RavenDB license and the *setup package*.

## Usage

### Prerequisites

- [RavenDB License](#getting-the-license)

- [RavenDB Setup Package](#creating-a-ravendb-setup-package)

- [Running an ingress controller](#set-up-your-ingress-controller)

If you have these, you can jump straight to [Installation](#installation).

### Getting the license

To run this Helm chart you need to acquire a RavenDB license. A free community license is available for production and can be obtained [here](https://ravendb.net/buy). If you just try things out off-prod, you can get a free developer license [here](https://ravendb.net/license/request/dev). 


### Creating a RavenDB Setup Package

This package contains certificates and the initial configuration required to initialize the cluster.
To create RavenDB Setup Package you can use the [rvn](https://github.com/ravendb/ravendb/tree/v7.0/tools/rvn) command line utility. The rvn utility generates proper Setup Package and values.yaml for you. 

Run rvn to generate helm values.yaml and a setup package:

```bash
# Scaffold rvn's setup.json file (optional)
rvn init-setup-params -m=[setup-mode] -o ./setup.json
```
Where setup-mode is 'lets-encrypt', 'own-certificate' or 'unsecured'.

Example `setup.json` after customization:
```json
{
  "License": {
    "Id": "...",
    "Name": "...",
    "Keys": [
             "",
             ""
         ]
  },
  "Email": "example@domain.com",
  "Domain": "domain-name-to-claim",
  "RootDomain": "development.run", 
  "NodeSetupInfos": {
    "A": {
      "PublicServerUrl": "https://a.domain-name-to-claim.development.run",
      "PublicTcpServerUrl": "tcp://a-tcp.domain-name-to-claim.development.run:38888",
      "Port": 443,
      "TcpPort": 38888,
      "Addresses": [
        "0.0.0.0"
      ]
    },
    "B": {
      "PublicServerUrl": "https://b.domain-name-to-claim.development.run",
      "PublicTcpServerUrl": "tcp://b-tcp.domain-name-to-claim.development.run:38888",
      "Port": 443,
      "TcpPort": 38888,
      "Addresses": [
        "0.0.0.0"
      ]
    },
    "C": {
      "PublicServerUrl": "https://c.domain-name-to-claim.development.run",
      "PublicTcpServerUrl": "tcp://c-tcp.domain-name-to-claim.development.run:38888",
      "Port": 443,
      "TcpPort": 38888,
      "Addresses": [
        "0.0.0.0"
      ]
    }
  }
}
```

```bash
# Create RavenDB Setup Package
rvn create-setup-package -m=[setup-mode] -s="[path/to/create-setup-package-setup.json]" -o=[package output path] --generate-helm-values="[yaml output path]"
```

If in doubt try `rvn [command] --help`.


### Customize Helm values.yaml file

Once the setup package generated, the `values.yaml` file can be fine-tuned for your environment.
Key configuration options include:
- Define `storageSize` for each node.
- Select desired RavenDB image tag. It is latest by default, but we don't recommend using this tag on production (due to its floating nature), tags on [DockerHub](https://hub.docker.com/r/ravendb/ravendb/tags).

- In some cases you might want to edit the [image pull policy](https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy).

- Provide custom `ingressClassName`. 

#### Example values.yaml

```yaml
# customizable
storageSize: 5Gi
ravenImageTag: latest
imagePullPolicy: IfNotPresent

# these values are generated by the script and shouldn't be changed
nodeTags:
- A
- B
- C
domain: "ravendb.poisson.net"
email: user@example.net
setupMode: LetsEncrypt
license: < license json >

# optional, for hackers
environment:
  SOME_ENV_VALUE: 'foo'
  SOME_OTHER_ENV_VALUE: 'bar'
```

## External Access & ingress controllers

When deploying a secure RavenDB cluster in Kubernetes, your ingress controller must support **SSL passthrough**. This is essential because RavenDB uses TLS for both HTTPS and TCP traffic, and the TLS connection must be terminated **at the RavenDB server itself**, not by the ingress controller. This allows proper handling of client certificates, SNI (Server Name Indication), and secure cluster communications.

### Traefik
Traefik natively supports TCP routing through [IngressRouteTCP](https://doc.traefik.io/traefik/reference/routing-configuration/kubernetes/crd/tcp/ingressroutetcp/). It's a recommended external access solution for RavenDB clusters that live inside Kubernetes. For detailed deployment guide, follow steps 1-5 from RavenDB Operator [Traefik guide](https://github.com/ravendb/ravendb-operator/blob/main/examples/networking/external_access/traefik/readme.md). This Helm chart deploys a Kubernetes Service for each node tag (e.g. `ravendb-a`, `ravendb-b`, `ravendb-c`) that expose both HTTP(S) and TCP ports, meaning you need to create two IngressRouteTCPs for each node tag (HTTPS and TCP).

Example `IngressRouteTCP` definition:
```yaml
# ingressRouteTCP.yaml
apiVersion: traefik.io/v1alpha1
kind: IngressRouteTCP
metadata:
  name: ravendb-a-https
  namespace: ravendb
spec:
  entryPoints:
    - websecure
  routes:
    - match: HostSNI(`a.example.run`)
      services:
        - name: ravendb-a
          port: 443
  tls:
    passthrough: true
---
apiVersion: traefik.io/v1alpha1
kind: IngressRouteTCP
metadata:
  name: ravendb-a-tcp
  namespace: ravendb
spec:
  entryPoints:
    - tcp
  routes:
    - match: HostSNI(`a-tcp.example.run`)
      services:
        - name: ravendb-a-tcp
          port: 38888
  tls:
    passthrough: true
---
# ... repeat for each node tag ...
```

### NGINX

**Warning**: ingress-nginx is **deprecated** (https://www.kubernetes.dev/blog/2025/11/12/ingress-nginx-retirement/) and no longer supported. The contnet below is left for historical reasons. To use it anyway, you need to explicitly define `ingressClassName: nginx` in your `values.yaml`.


```
To use NGINX as your ingress controller, ensure it is deployed with SSL passthrough enabled using the `--enable-ssl-passthrough` flag.

If you've deployed k8s nginx before, its dependencies are frequently stored in the 'ingress-nginx' namespace.
You can deploy nginx to k8s using the `nginx-ingress-ravendb.yaml` file located in the misc folder, which is preconfigured for default nodes/tags/ports and secured connection.
It is not necessary, but running `kubectl delete all --all -n ingress-nginx` should delete all nginx k8s depts before another deployment.
Run `kubectl apply -f [path to 'nginx-ingress-ravendb' file]` to either update or install well configured nginx ingress controller locally.

> **Note:** When using the `nginx-ingress-ravendb.yaml` configuration, you must advertise the TCP endpoint using port 443 in your `setup.json`—for example:  
> `"PublicTcpServerUrl": "tcp://a.my-domain.development.run:443"`  
>
> This is required because the NGINX Ingress Controller (configured with `--enable-ssl-passthrough`) only exposes TCP via port 443.  

If you want to configure it manually, make sure that...
- ... port 38888 (or your own ServerUrl_Tcp port) is exposed on the nginx controller pod
- ... --enable-ssl-passthrough is set (when working with secured cluster)
```

### Other external access solutions

If you're using any other ingress controller that leverages `Ingress` resource definition, update the `ingressClassName` in your values.yaml file to match the class name used by your deployed ingress controller. 
For example: `ingressClassName: haproxy`.
You can request support for your ingress controller by submitting an issue to this repository.


This Helm chart doesn't support [GatewayAPI](https://gateway-api.sigs.k8s.io/guides/getting-started/), as [TCP routing](https://gateway-api.sigs.k8s.io/guides/tcp/) future support at this point remains unclear. Submit an issue to this repository if you'd like to request this functionality.

### Installation

**via [artifacthub.io](https://artifacthub.io/packages/helm/ravendb-cluster/ravendb)**

```
helm repo add ravendb https://ravendb.github.io/helm-charts/charts

helm install [your-custom-name] ravendb/ravendb-cluster --set-file package=[setup/package/path] -f [values/yaml/path]
```

or by *cloning* the repo

```
git clone https://github.com/ravendb/helm-charts.git

helm install [name] [chart path] --set-file package=[path/to/package.zip] -f [path/to//values.yaml]
```

The chart is located under the `charts/ravendb-cluster` directory.

## Rolling updates

You can perform rolling update using the `rolling-update.sh` script located in the `/scripts` directory. Provide desired RavenDB image tag from the DockerHub https://hub.docker.com/r/ravendb/ravendb/tags as the first arg and path to the Helm chart as the second.

```
./rolling-update.sh latest ~/ravendb-cluster
```

It'll execute rolling update strategy and update your pods image tags.
